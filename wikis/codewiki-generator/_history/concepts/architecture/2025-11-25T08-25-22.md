# CodeWiki-Generator Architecture

## System Overview

CodeWiki-Generator is an intelligent documentation automation system that transforms software repositories into comprehensive, navigable wikis through AI-powered analysis. The system leverages multiple specialized agents to analyze code, extract patterns, generate documentation, and create cross-linked content that maintains itself as repositories evolve. By combining repository introspection, commit history analysis, and contextual AI generation, it produces living documentation that captures both implementation details and architectural insights without manual intervention.

## Core Architecture

The system implements a **Multi-agent documentation generation architecture** where specialized AI agents collaborate in a coordinated pipeline. Each agent has a distinct responsibility—code analysis, content generation, linking, or meta-analysis—and operates with **Agent-based Documentation Pipeline** coordination. The architecture follows **Cost-aware API consumption** principles to manage LLM usage efficiently while maintaining quality through **Resilient API Communication with Exponential Backoff** patterns.

The system is built around **Repository-scale batch processing with resumable state**, allowing it to handle large codebases incrementally while maintaining processing continuity across runs. **Category-based Documentation Organization** ensures content is properly structured and discoverable, while **Contextual Metadata Enrichment Pattern** maintains rich relationships between generated content.

## Major Components

### ArchitectureOverviewAgent
Serves as the primary system coordinator, analyzing repository structure and generating high-level architectural documentation. This agent performs **Repository structure analysis for guide generation** and implements **Hierarchical content discovery and retrieval** to understand codebase organization patterns.

### Code Analysis Agent
Handles deep repository inspection through **Source code organization pattern** analysis and **Intelligent File Filtering for Analysis**. It extracts meaningful code patterns, identifies key components, and feeds structured insights to other agents for content generation.

### Documentation Writer Agent
Transforms analytical insights into human-readable documentation using **AI-driven content generation with formatting normalization**. Implements **LLM Response Cleaning and Normalization** to ensure consistent output quality and **Markdown Response Sanitization** for safe content generation.

### WikiIndexAgent / Wiki Index Agent
Manages the overall wiki structure through **Wiki Markdown Management System** and **Category-based wiki content organization**. Coordinates **Multi-category wiki aggregation pattern** to maintain navigable content hierarchies.

### Cross-page linking system
Implements **Multi-agent linking workflow** and **Search and relationship graph for content linking** to create intelligent connections between documentation pages. Uses **Content-aware mention detection** and **Cross-page link discovery system** to build semantic relationships.

### MetaAnalysisAgent
Provides system-wide insights through **Meta-analysis agent for documentation patterns** and **Periodic meta-analysis integration**. Identifies documentation gaps, suggests improvements, and maintains quality metrics across the generated wiki.

### ClaudeClient / Anthropic SDK wrapper
Manages all AI interactions with **Cost-Bounded Processing with Statistics Tracking** and **Lazy-loaded External Dependencies**. Provides **Cost-aware API usage tracking** to prevent runaway costs while maintaining service reliability.

## Data Flow

The system processes repositories through a **Two-phase Documentation Generation Pipeline**:

```
Repository Input
      ↓
  Code Analysis Agent → Repository Structure Analysis
      ↓
  Content Generation Phase:
    ├─ ArchitectureOverviewAgent → High-level docs
    ├─ Documentation Writer Agent → Detailed content  
    └─ GuideGenerationAgent → Operational guides
      ↓
  Wiki Assembly Phase:
    ├─ WikiIndexAgent → Structure organization
    ├─ Cross-page linking system → Relationship building
    └─ MetaAnalysisAgent → Quality assessment
      ↓
  Wiki Output + State Persistence
```

**Commit-driven documentation pipeline** ensures updates flow through the same stages when repositories change. **Persistent State Management with Validation** allows resuming interrupted processing, while **Processing statistics and execution reporting** provide visibility into system operation.

The **Contextual wiki retrieval** system enables agents to access previously generated content for cross-referencing and link discovery, creating a feedback loop that improves content quality over iterations.

## Key Design Decisions

### Agent-Based Architecture Over Monolithic Processing
**Choice**: Separate specialized agents rather than single large processor  
**Rationale**: Each documentation concern (analysis, generation, linking, organization) requires different expertise and can be optimized independently. Agents can be developed, tested, and scaled separately.  
**Trade-offs**: Added coordination complexity and state management overhead, but gained modularity, testability, and the ability to swap agent implementations.

### Cost-Aware Processing with Budget Controls
**Choice**: Implement comprehensive API cost tracking and limits  
**Rationale**: LLM APIs represent the primary operational cost and can scale unpredictably with repository size. **Cost-Bounded Processing with Statistics Tracking** prevents runaway expenses.  
**Trade-offs**: Additional complexity in request management and potential processing limitations, but gained predictable operational costs and system sustainability.

### Resumable State Architecture
**Choice**: **Persistent State Management with Validation** for all processing stages  
**Rationale**: Large repositories may require hours of processing, and network/API failures are inevitable. Resumable processing prevents losing work and enables incremental updates.  
**Trade-offs**: Increased storage requirements and state management complexity, but gained reliability and efficiency for large-scale processing.

### Category-Based Organization Over Flat Structure  
**Choice**: **Category-based Documentation Organization** with hierarchical navigation  
**Rationale**: Generated wikis need to be navigable and maintainable as they grow. Categories provide logical groupings that scale with repository complexity.  
**Trade-offs**: More complex wiki management logic, but significantly improved user experience and content discoverability.

### Test Environment Isolation
**Choice**: **Test-Mode Dependency Injection** and **Environment-driven configuration**  
**Rationale**: Documentation generation involves external API calls and file system operations that need isolation during testing. Mock injection enables comprehensive testing without costs.  
**Trade-offs**: Additional configuration complexity, but gained reliable test coverage and development workflow efficiency.

## Extension Points

The system provides several well-defined extension points for customization:

**Agent Extension**: New agents can be added to the **Multi-agent documentation generation architecture** by implementing the standard agent interface and registering with the coordinator. Custom agents can handle specialized content types or analysis patterns.

**Template Customization**: The **Template management system with caching** allows custom documentation templates and formatting rules. Templates can be repository-specific or globally applied based on content categories.

**Processing Pipeline Hooks**: **Conditional Post-Processing** and **Processor-based page operations** enable custom processing steps at any pipeline stage. Extensions can add validation, transformation, or enrichment operations.

**Configuration Extensions**: The **Singleton configuration module** supports custom settings and **Environment-based configuration** for deployment-specific behavior. New configuration sections integrate automatically with the validation system.

**Content Discovery**: **Intelligent File Filtering for Analysis** can be extended with custom rules for specific repository types or content patterns. New filters integrate with the existing **Repository introspection for context enrichment** system.

**State Management**: The **State Schema Validation Pattern** allows extensions to add custom state tracking and **Processing state lifecycle** management for specialized processing requirements.
