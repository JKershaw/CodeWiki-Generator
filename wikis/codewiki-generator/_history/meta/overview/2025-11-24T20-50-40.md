---
title: Overview
category: meta
sourceFile: README.md
created: 2025-11-24
updated: 2025-11-24
---

# CodeWiki Generator Overview

An intelligent documentation automation system that analyzes software repositories and generates comprehensive wiki-style documentation using Large Language Model (LLM) agents.

## Core Philosophy

**Code tells you what. Documentation tells you why. History tells you how.**

CodeWiki Generator automatically analyzes your codebase, discovers architectural patterns, and produces structured markdown documentation organized into concepts, components, and guides. The system practices **wiki-driven development**: build features, generate documentation about them, read what was generated, and use that feedback to improve both the system and its output.

## Key Features

- **AI-Powered Documentation**: Uses Claude Sonnet 4.5 to analyze code and generate clear, insightful documentation
- **Specialized Agent System**: Dedicated agents for code analysis, documentation writing, architecture overview, and guide generation
- **Cross-Page Linking**: Automatic hyperlink discovery and injection for seamless navigation
- **Category-Based Organization**: Documents organized into concepts/, components/, and guides/
- **Repository Fingerprinting**: Analyzes repository structure to guide documentation generation
- **Resilient LLM Parsing**: Progressive JSON repair for handling unreliable LLM outputs
- **Self-Documenting**: The system successfully documents its own architecture (meta-validation)
- **MCP Server Integration**: Claude Code and other AI tools can query generated documentation via Model Context Protocol

## Current Status

**Production-Ready Core | 87% Quality | 18 Pages Generated**

The system has validated itself by successfully documenting its own architecture:

| Metric | Result |
|--------|--------|
| **Overall Quality** | 87% (Grade A) |
| **Navigation** | 90% (cross-page linking) |
| **Completeness** | 85% (all major components) |
| **Usability** | 88% (actionable guides) |

**Documentation Generated**:
- 9 concepts (architectural patterns and design decisions)
- 4 components (implementation modules)
- 4 guides (operational documentation)
- 1 index (auto-generated navigation)

See **WIKI_COMPARISON_ASSESSMENT.md** for detailed quality analysis comparing auto-generated documentation to manually-written equivalents.

## How It Works

The system follows an **architecture synthesis agent pattern** where specialized LLM agents collaborate:

```
Repository → Fingerprinting → Agent Dispatch → Documentation Assembly
                                     ↓
              ┌─────────────────────┼─────────────────────┐
              │                     │                     │
    ArchitectureOverviewAgent  CodeAnalysisAgent  GuideGenerationAgent
              │                     │                     │
              └─────────────────────┼─────────────────────┘
                                    ↓
                           JSON Response Cleaning
                                    ↓
                      Category-Based Content Organization
                                    ↓
                        Wiki Index with Auto-Navigation
                                    ↓
                           Markdown Documentation
```

### Processing Pipeline

1. **Repository Analysis**: Fingerprints repository structure and identifies patterns
2. **Agent Dispatch**: Routes analysis to specialized LLM agents based on content type
3. **Content Generation**: Each agent generates documentation for its domain
4. **Quality Assurance**: Progressive JSON repair and response validation
5. **Assembly**: Organizes content into category-based structure (concepts, components, guides)
6. **Linking**: Discovers mentions and injects cross-page hyperlinks automatically
7. **Index Generation**: Creates navigable table of contents

## Architecture Components

The system is composed of specialized modules:

- **Processor** - Orchestrates analysis and documentation generation workflow
- **ArchitectureOverviewAgent** - Synthesizes high-level architectural insights
- **CodeAnalysisAgent** - Analyzes code structure and patterns
- **DocumentationWriterAgent** - Generates markdown with code examples
- **GuideGenerationAgent** - Creates operational and setup guides
- **LinkDiscoveryAgent** - Discovers mentions and injects cross-page hyperlinks
- **WikiManager** - Handles markdown file operations and storage
- **WikiIndexAgent** - Generates navigation structure and index pages

## Getting Started

### Installation

```bash
git clone <repository-url>
cd CodeWiki-Generator
npm install
npm test
```

### Generate Documentation

```bash
# Generate wiki for this project
node generate-self-wiki.js

# Or use programmatically
const Processor = require('./lib/processor');
const processor = new Processor('./output-wiki');
await processor.processRepository('https://github.com/owner/repo');
```

For detailed instructions, see the Getting Started guide.

## MCP Server Integration

The Model Context Protocol server enables AI assistants like Claude Code to query your generated wiki documentation for context while developing.

### Starting the Server

```bash
npm run mcp-server
# Or with custom wiki path
node mcp-server.js --wiki ./wikis/your-project
```

### Available Tools

- **query_wiki**: Search the wiki for relevant documentation based on task descriptions
- **request_documentation**: Queue documentation requests for topics not yet covered

### Using with Claude Code

Configure Claude Code to connect to the MCP server:

```json
{
  "mcpServers": {
    "codewiki": {
      "command": "node",
      "args": ["/path/to/CodeWiki-Generator/mcp-server.js"]
    }
  }
}
```

Once configured, Claude Code can answer questions like "How do I run tests?" or "What's the architecture?" by automatically querying the wiki.

## Quality Assessment

Auto-generated documentation achieves **87% quality** compared to manually-written alternatives.

### Strengths

- ✅ Explains design rationale and trade-offs better than typical manual wikis
- ✅ Comprehensive cross-page navigation with automatic hyperlinking
- ✅ Coherent narrative explaining system architecture from multiple angles
- ✅ Immediately useful Getting Started guide and setup instructions

### Current Limitations

- Code examples extracted from tests (good foundation for improvement)
- Test coverage statistics could be more comprehensive
- Some component relationships could include more implementation detail

## Prerequisites & Setup

**Requirements**:
- Node.js 24.x or higher (tested on 22.x with warnings)
- Git (for repository analysis)
- Anthropic API key (optional for production; tests use mocks)

**Environment**:
```bash
cp .env.example .env
# Add: ANTHROPIC_API_KEY=your_key_here
```

Note: API keys are not required for running tests. All tests use mocks to avoid API costs.

## Testing & Validation

- **220+ passing tests** with comprehensive coverage
- Unit tests for all agents and core components
- Integration tests for complete workflows
- All tests use mocks — no API costs incurred

The system validates itself through dogfooding: the quality of auto-generated documentation for this codebase proves the system works as described.

## Cost Estimation

- Processing ~100 commits: $3-$5 (Claude Sonnet 4.5)
- Average per commit: $0.03-$0.05
- Self-documentation run: ~$1-$2

## Roadmap

**✅ Completed**:
- Core Infrastructure (WikiManager, StateManager, GitHub Integration)
- AI Agent System (all specialized agents)
- Processing Engine (repository processing, state persistence)
- Cross-page linking and code examples
- MCP Server integration with Claude Code

**⏸️ Planned**:
- Web Dashboard interface (Phase 4)
- Incremental update mode (process only new commits)
- Enhanced MCP server features (advanced metrics, prompts)

## Development Philosophy

This project practices **wiki-driven development**:

1. Build a feature
2. Run the wiki generator on this codebase
3. Read the generated documentation
4. If unclear, improve the documentation system
5. Iterate to the next feature

**The quality of our self-generated documentation validates the quality of the system itself.** This is both a design principle and a validation mechanism—if the system couldn't document its own codebase well, it wouldn't be suitable for documenting other projects.

## Contributing

Key areas for contribution:
- Web dashboard implementation (Phase 4)
- Test coverage extraction and reporting
- Additional specialized agents for domain-specific documentation
- Performance optimizations and incremental processing

---

**Self-Validation**: This system successfully documented its own architecture at 87% quality. The generated wiki serves as proof that the system works as described.